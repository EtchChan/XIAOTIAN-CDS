{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452c9efe-e10c-421a-bb11-880ef58cb6f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f29e8a-7ee8-418f-b00a-8f291ec82cce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11l.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"VisDrone.yaml\", epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb821f88-e924-468c-90bf-443b1b4f444a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-12T12:40:11.370629Z",
     "iopub.status.busy": "2024-10-12T12:40:11.370250Z",
     "iopub.status.idle": "2024-10-12T12:40:21.726008Z",
     "shell.execute_reply": "2024-10-12T12:40:21.725464Z",
     "shell.execute_reply.started": "2024-10-12T12:40:11.370594Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.4 ðŸš€ Python-3.10.14 torch-2.3.1+cu121 CUDA:0 (NVIDIA A10, 22732MiB)\n",
      "YOLO11n summary (fused): 238 layers, 2,584,102 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/workspace/yolo/datasets/VisDrone/VisDrone2019-DET-val/labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:07<00:00,  4.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.553      0.286      0.423      0.273\n",
      "            pedestrian        520       8844      0.617      0.289      0.464      0.235\n",
      "                people        482       5125      0.657      0.175      0.412      0.184\n",
      "               bicycle        364       1287      0.291     0.0668      0.167     0.0798\n",
      "                   car        515      14064      0.759      0.711      0.779      0.576\n",
      "                   van        421       1975       0.57      0.317      0.446      0.347\n",
      "                 truck        266        750      0.598      0.277      0.445      0.324\n",
      "              tricycle        337       1045       0.46      0.194      0.312       0.21\n",
      "       awning-tricycle        220        532      0.308     0.0921      0.181      0.132\n",
      "                   bus        131        251      0.667      0.462       0.59      0.432\n",
      "                 motor        485       4886      0.599      0.277      0.434      0.214\n",
      "Speed: 0.2ms preprocess, 0.8ms inference, 0.0ms loss, 2.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val12\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"runs/detect/train2/weights/best.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.val(data=\"VisDrone.yaml\", imgsz=640, batch=16, conf=0.25, iou=0.6, device=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f959728-d63c-4def-9bfe-80dbb2f21dc2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-12T12:35:41.174310Z",
     "iopub.status.busy": "2024-10-12T12:35:41.173928Z",
     "iopub.status.idle": "2024-10-12T12:35:52.401099Z",
     "shell.execute_reply": "2024-10-12T12:35:52.400430Z",
     "shell.execute_reply.started": "2024-10-12T12:35:41.174275Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.4 ðŸš€ Python-3.10.14 torch-2.3.1+cu121 CUDA:0 (NVIDIA A10, 22732MiB)\n",
      "YOLO11s summary (fused): 238 layers, 9,416,670 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/workspace/yolo/datasets/VisDrone/VisDrone2019-DET-val/labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:08<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.594      0.358      0.479      0.319\n",
      "            pedestrian        520       8844      0.657       0.36      0.529      0.283\n",
      "                people        482       5125       0.67      0.233      0.449       0.21\n",
      "               bicycle        364       1287      0.368      0.137      0.234      0.122\n",
      "                   car        515      14064      0.799      0.752      0.813      0.619\n",
      "                   van        421       1975      0.592      0.429      0.511      0.399\n",
      "                 truck        266        750      0.635      0.351      0.502      0.376\n",
      "              tricycle        337       1045      0.462      0.296      0.363      0.234\n",
      "       awning-tricycle        220        532      0.359       0.15      0.227      0.168\n",
      "                   bus        131        251      0.769      0.478      0.651      0.513\n",
      "                 motor        485       4886      0.625      0.392      0.508      0.268\n",
      "Speed: 0.2ms preprocess, 1.7ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"runs/detect/train3/weights/best.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.val(data=\"VisDrone.yaml\", imgsz=640, batch=16, conf=0.25, iou=0.6, device=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "582d9b5e-4e90-41ea-a06f-516be9ba9e5c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-12T12:42:01.555277Z",
     "iopub.status.busy": "2024-10-12T12:42:01.554949Z",
     "iopub.status.idle": "2024-10-12T12:42:14.359943Z",
     "shell.execute_reply": "2024-10-12T12:42:14.359352Z",
     "shell.execute_reply.started": "2024-10-12T12:42:01.555250Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.4 ðŸš€ Python-3.10.14 torch-2.3.1+cu121 CUDA:0 (NVIDIA A10, 22732MiB)\n",
      "YOLO11m summary (fused): 303 layers, 20,037,742 parameters, 0 gradients, 67.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/workspace/yolo/datasets/VisDrone/VisDrone2019-DET-val/labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:09<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759       0.61      0.427      0.525      0.357\n",
      "            pedestrian        520       8844      0.687      0.439      0.588      0.326\n",
      "                people        482       5125        0.7        0.3      0.494      0.246\n",
      "               bicycle        364       1287      0.374      0.207      0.284      0.155\n",
      "                   car        515      14064      0.828      0.779      0.836      0.651\n",
      "                   van        421       1975       0.59      0.497      0.545      0.429\n",
      "                 truck        266        750      0.618      0.419      0.536      0.404\n",
      "              tricycle        337       1045      0.492      0.368      0.412       0.27\n",
      "       awning-tricycle        220        532      0.429      0.192      0.283       0.21\n",
      "                   bus        131        251      0.772      0.594      0.723      0.583\n",
      "                 motor        485       4886      0.614      0.474      0.548      0.298\n",
      "Speed: 0.2ms preprocess, 4.7ms inference, 0.0ms loss, 5.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val14\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"runs/detect/train4/weights/best.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.val(data=\"VisDrone.yaml\",  imgsz=640, batch=16, conf=0.25, iou=0.6, device=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9878551a-8492-480b-babb-4be9d4c19181",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-12T12:42:43.014942Z",
     "iopub.status.busy": "2024-10-12T12:42:43.014603Z",
     "iopub.status.idle": "2024-10-12T12:42:56.705453Z",
     "shell.execute_reply": "2024-10-12T12:42:56.704907Z",
     "shell.execute_reply.started": "2024-10-12T12:42:43.014919Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.4 ðŸš€ Python-3.10.14 torch-2.3.1+cu121 CUDA:0 (NVIDIA A10, 22732MiB)\n",
      "YOLO11l summary (fused): 464 layers, 25,287,022 parameters, 0 gradients, 86.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/workspace/yolo/datasets/VisDrone/VisDrone2019-DET-val/labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:10<00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.624      0.421      0.529      0.362\n",
      "            pedestrian        520       8844      0.711      0.418      0.588      0.326\n",
      "                people        482       5125      0.708      0.283       0.49      0.243\n",
      "               bicycle        364       1287       0.38      0.218      0.291      0.162\n",
      "                   car        515      14064      0.833      0.777      0.835      0.653\n",
      "                   van        421       1975      0.619      0.471      0.556      0.444\n",
      "                 truck        266        750      0.656      0.448      0.566      0.423\n",
      "              tricycle        337       1045      0.499      0.352      0.412      0.275\n",
      "       awning-tricycle        220        532      0.402      0.197      0.273      0.204\n",
      "                   bus        131        251       0.79       0.57      0.715      0.579\n",
      "                 motor        485       4886      0.637      0.481      0.566      0.308\n",
      "Speed: 0.2ms preprocess, 9.2ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val16\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"runs/detect/train5/weights/best.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Train the model\n",
    "results = model.val(data=\"VisDrone.yaml\", epochs=100, imgsz=640, batch=16, conf=0.25, iou=0.6, device=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54384dee-e3c9-4c3f-923d-ddcc51ce7467",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-05T12:38:11.536766Z",
     "iopub.status.busy": "2024-10-05T12:38:11.536408Z",
     "iopub.status.idle": "2024-10-05T12:40:04.637845Z",
     "shell.execute_reply": "2024-10-05T12:40:04.637247Z",
     "shell.execute_reply.started": "2024-10-05T12:38:11.536743Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.4 ðŸš€ Python-3.10.14 torch-2.3.1+cu121 CUDA:0 (NVIDIA A10, 22732MiB)\n",
      "Loading runs/detect/train5/weights/best_openvino_model for OpenVINO inference...\n",
      "Using OpenVINO LATENCY mode for batch=1 inference...\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/workspace/yolo/datasets/VisDrone/VisDrone2019-DET-val/labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [01:49<00:00,  4.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.622      0.422      0.528      0.361\n",
      "            pedestrian        520       8844       0.71      0.416      0.586      0.324\n",
      "                people        482       5125       0.71      0.283      0.491      0.242\n",
      "               bicycle        364       1287      0.374      0.217      0.289      0.158\n",
      "                   car        515      14064       0.83      0.779      0.834      0.653\n",
      "                   van        421       1975      0.622       0.47      0.556      0.442\n",
      "                 truck        266        750      0.658      0.447      0.563      0.419\n",
      "              tricycle        337       1045      0.488      0.358      0.409      0.274\n",
      "       awning-tricycle        220        532      0.408      0.203      0.278      0.207\n",
      "                   bus        131        251      0.781       0.57      0.712      0.577\n",
      "                 motor        485       4886      0.639      0.482      0.565      0.309\n",
      "Speed: 2.5ms preprocess, 178.3ms inference, 0.0ms loss, 6.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "# model = YOLO(\"runs/detect/train5/weights/best.pt\")\n",
    "# Export the model\n",
    "# model.export(format=\"openvino\")  # creates 'yolov8n_openvino_model/'\n",
    "# Load the exported OpenVINO model\n",
    "ov_model = YOLO(\"runs/detect/train5/weights/best_openvino_model/\")\n",
    "validation_results = ov_model.val(data=\"VisDrone.yaml\", imgsz=640, batch=16, conf=0.25, iou=0.6, device=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7891ccb-fa9b-463b-90f9-c9d937e42784",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-05T12:44:56.290399Z",
     "iopub.status.busy": "2024-10-05T12:44:56.289772Z",
     "iopub.status.idle": "2024-10-05T12:48:20.180724Z",
     "shell.execute_reply": "2024-10-05T12:48:20.180010Z",
     "shell.execute_reply.started": "2024-10-05T12:44:56.290375Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.4 ðŸš€ Python-3.10.14 torch-2.3.1+cu121 CUDA:0 (NVIDIA A10, 22732MiB)\n",
      "Loading runs/detect/train5/weights/best.onnx for ONNX Runtime inference...\n",
      "Setting batch=1 input of shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/workspace/yolo/datasets/VisDrone/VisDrone2019-DET-val/labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [03:19<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.622      0.422      0.528      0.361\n",
      "            pedestrian        520       8844       0.71      0.416      0.586      0.324\n",
      "                people        482       5125       0.71      0.283      0.491      0.242\n",
      "               bicycle        364       1287      0.374      0.217      0.289      0.158\n",
      "                   car        515      14064       0.83      0.779      0.834      0.653\n",
      "                   van        421       1975      0.622       0.47      0.556      0.442\n",
      "                 truck        266        750      0.658      0.447      0.563      0.419\n",
      "              tricycle        337       1045      0.488      0.358      0.409      0.274\n",
      "       awning-tricycle        220        532      0.408      0.203      0.278      0.207\n",
      "                   bus        131        251      0.781       0.57      0.712      0.577\n",
      "                 motor        485       4886      0.639      0.482      0.565      0.309\n",
      "Speed: 0.2ms preprocess, 352.8ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "# model = YOLO(\"runs/detect/train5/weights/best.pt\")\n",
    "# model.export(format=\"onnx\") \n",
    "onnx_model = YOLO(\"runs/detect/train5/weights/best.onnx\")\n",
    "validation_results = onnx_model.val(data=\"VisDrone.yaml\", imgsz=640, batch=16, conf=0.25, iou=0.6, device=\"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49bb33b0-9a47-4d9a-a68f-0b0c60c9a4db",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-10-05T12:55:03.665350Z",
     "iopub.status.busy": "2024-10-05T12:55:03.664964Z",
     "iopub.status.idle": "2024-10-05T12:55:29.779979Z",
     "shell.execute_reply": "2024-10-05T12:55:29.779331Z",
     "shell.execute_reply.started": "2024-10-05T12:55:03.665325Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.4 ðŸš€ Python-3.10.14 torch-2.3.1+cu121 CUDA:0 (NVIDIA A10, 22732MiB)\n",
      "Loading runs/detect/train5/weights/best.engine for TensorRT inference...\n",
      "[10/05/2024-20:55:03] [TRT] [I] Loaded engine size: 120 MiB\n",
      "[10/05/2024-20:55:03] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +74, now: CPU 1, GPU 190 (MiB)\n",
      "[10/05/2024-20:55:03] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/workspace/yolo/datasets/VisDrone/VisDrone2019-DET-val/labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:09<00:00, 56.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.622      0.423      0.529      0.361\n",
      "            pedestrian        520       8844       0.71      0.416      0.586      0.324\n",
      "                people        482       5125      0.709      0.283       0.49      0.242\n",
      "               bicycle        364       1287      0.377      0.218       0.29       0.16\n",
      "                   car        515      14064      0.829      0.779      0.835      0.652\n",
      "                   van        421       1975      0.621       0.47      0.556      0.442\n",
      "                 truck        266        750      0.659      0.448      0.564       0.42\n",
      "              tricycle        337       1045      0.489      0.357      0.409      0.274\n",
      "       awning-tricycle        220        532       0.41      0.205      0.279      0.207\n",
      "                   bus        131        251      0.781       0.57      0.713      0.577\n",
      "                 motor        485       4886      0.638      0.482      0.565      0.309\n",
      "Speed: 0.2ms preprocess, 7.2ms inference, 0.1ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "# model = YOLO(\"runs/detect/train5/weights/best.pt\")\n",
    "# model.export(format=\"engine\") \n",
    "rt_model = YOLO(\"runs/detect/train5/weights/best.engine\")\n",
    "validation_results = rt_model.val(data=\"VisDrone.yaml\", imgsz=640, batch=16, conf=0.25, iou=0.6, device=\"0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
